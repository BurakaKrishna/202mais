# -*- coding: utf-8 -*-
"""Prediction Test Refactored

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OgiCsv3V-lcq9NEex4zAiPd2vW2SmuCh
"""

# Get dataset
!wget -O "./GSE87571_Matrix_Avg_Beta.txt.gz" "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE87571&format=file&file=GSE87571%5Fmatrix1of2%2Etxt%2Egz"
!wget -O "./GSE87571_Matrix_Avg_Beta2.txt.gz" "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE87571&format=file&file=GSE87571%5Fmatrix2of2%2Etxt%2Egz"

# Extract dataset
!gunzip "./GSE87571_Matrix_Avg_Beta.txt.gz"
!gunzip "./GSE87571_Matrix_Avg_Beta2.txt.gz"

# Merge prepare to merge text files
!cut -d$'\t' -f1 --complement "./GSE87571_Matrix_Avg_Beta2.txt" > newFile && mv newFile "./GSE87571_Matrix_Avg_Beta2.txt"

# Merge text files
!paste "GSE87571_Matrix_Avg_Beta.txt" "./GSE87571_Matrix_Avg_Beta2.txt" > matrix.csv

# Remove every other column because every other column has blank values
!awk '{{printf "%s ", $1}for(i=2;i<=NF;i=i+2){printf "%s ", $i}{printf "%s", RS}}' matrix.csv > cut_matrix.csv

# Get a sneak peak
!head -5 matrix.csv
!head -5 cut_matrix.csv

# Commented out IPython magic to ensure Python compatibility.
# Import necessary libraries

import pandas as pd
import numpy as np
import random as rd
from sklearn.decomposition import PCA
from sklearn import preprocessing
import matplotlib.pyplot as plt # NOTE: This was tested with matplotlib v. 2.1.0
from sklearn.model_selection import train_test_split
from sklearn import metrics
import seaborn as sns

# import tensorflow

from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf

# Read data from txt file into dataframe
data = pd.read_csv("./cut_matrix.csv", sep=' ', low_memory=False, index_col = 0)
#data.set_index("ID_REF", inplace = True)

# Drop extra column
data.drop(columns=['Unnamed: 733'], inplace=True)

# Filtering for cgp values used by other research papers
spots16 = ["cg19761273", "cg27544190", "cg03286783", "cg01511567", "cg07158339", "cg05442902", "cg24450312", "cg17274064", "cg02085507", "cg20692569", "cg04528819", "cg08370996", "cg04084157", "cg22736354", "cg06493994", "cg02479575"]
spots6 = ["cg09809672", "cg22736354", "cg02228185", "cg01820374", "cg06493994", "cg19761273"]
spots19 = list(set(spots6 + spots16))
print(len(spots19))
data19 = data[data.index.isin(spots19)]
print(data19)

data_filter_19 = False

# Setup annotations

# decide between 19 cgp and full set
 if (data_filter_19):
   data_f = data19.T
 else:
   data_f = data.T
 
print(data_f)
#data_f = data_f.dropna(axis = 1)
#data_f = data_f.set_index("ID_REF")
#print(data_f)

# prepare index
annotations = pd.read_csv("GSE87571_series_matrix.csv", index_col=0, header=None).T
#print(annotations.columns)
print(annotations.head())
#print(annotations["Age"].head())
#print(annotations.tail)

#annotations.Sample_title = annotations.Sample_title.str[:annotations.Sample_title.str.index(" ")]
#print(annotations.Sample_title)

for i, title in enumerate(annotations["Sample_title"]):
  annotations["Sample_title"][i + 1] = title[:title.index(" ")]



annotations.set_index("Sample_title", inplace=True)
annotations.drop(["Tissue", "Disease"], axis=1, inplace=True)

annotations['Gender'] = annotations['Gender'].str.replace('gender: ','')
annotations['Age'] = (annotations['Age'].str.replace('age: ',''))

#print(annotations[~annotations[annotations['Age'].str.contains("NA")]])
#print(len(annotations[annotations.Age != 'NA']))



annotations.sort_index(inplace=True)
data_f.sort_index(inplace=True)
data_f = data_f.astype(float)
data_f["Age"] = annotations["Age"]

print(data_f.shape)
data_f.dropna(axis=1, inplace=True)
print(data_f.shape)
data_f = data_f[data_f.Age != "NA"]
data_f.Age = data_f.Age.astype(float)
print(data_f.shape)
print(data_f.head())

# Visualize data19 in heatmap and remove unwanted values
print(len(spots19))
data19 = data_f[spots19]
print(data19.shape)

#data19["Age"] = data_f.Age
data19 = data19.assign(Age = data_f.Age)
data19 = data19.sort_values("Age")
data19 = data19.dropna(axis=0, how='any')

print(data19.tail())
data19_ages = data19["Age"]
np.save("data19_ages.npy", data19_ages)
data19.drop("Age", inplace=True, axis=1)
data19 = data19.to_numpy()
np.save("data19.npy", data19)

ax = plt.axes()
sns.heatmap(data19.T, annot=False, ax = ax)

ax.set_title('Heatmap of Methylation Values')

ax.set_xlabel("Samples sorted ascending by age")
ax.set_ylabel("19 selected cgp positions")
plt.savefig('heatmap19.jpg')
print(data19_ages)

# Trying GradientBoostingRegressor Learning
from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor

#X_train, X_test, y_train, y_test = train_test_split(data_f, annotations["Age_Group"], test_size=0.10)
X_train, X_test, y_train, y_test = train_test_split(data19, data19_ages, test_size=0.10)

gb = GradientBoostingRegressor(loss='lad', learning_rate=0.03, n_estimators=300, max_features='log2', subsample = 0.6, min_samples_split=2, max_depth=4, verbose = 1, warm_start = True)
gb.fit(X_train, y_train)
y = gb.predict(X_test)

print(y.shape)
print(y_test.shape)

df = pd.DataFrame({"Real":y_test, "Pred":y.reshape(73)})
df = df.sort_values(by=['Real'])
plt.scatter(x = range(73), y = df.Pred, c = 'b')
plt.scatter(x = range(73), y = df.Real, c = 'r')
plt.show()
plt.scatter(x = df.Real, y = df.Pred, c = 'b')

X_train, X_test, y_train, y_test = train_test_split(data19, data19_ages, test_size=0.10)

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(512, activation='relu', input_shape=(19,)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1)
])


model.summary()

# Compile model
model.compile(loss= "mean_squared_error" , optimizer="adam", metrics=["mean_squared_error"])
model.fit(X_train, y_train.to_numpy(),  epochs=50, validation_data=(X_test, y_test.to_numpy()))

model.save("final_weights.h5")
model.save("keras.h5")

!pip install tensorflowjs

!mkdir model
!tensorflowjs_converter --input_format keras keras.h5 model/

!zip -r model.zip model

print(keras.V)

model.load_weights('model_weights.index')

# for generating submission
np.save("X_test.npy", X_test)
np.save("X_train.npy", X_train)
y = model.predict(X_test)
y_ = model.predict(X_train)

dfd = abs(y[:, 0] - y_test)
dfc = abs(y_test.mean() - y_test)
dfsum = pd.DataFrame(dfd < 10)
dfcsum = pd.DataFrame(dfc < 10)
print("Machine Learning:")
print(dfsum.sum() / len(dfsum))
print("Guess Mean:")
print(dfcsum.sum() / len(dfcsum))

##  Comparing Real and Predicted Ages by Index (Validation Set)
df = pd.DataFrame({"Real":y_test, "Pred":y.reshape(73)})
df = df.sort_values(by=['Real'])
pr = plt.scatter(x = range(73), y = df.Pred, c = 'b')
re = plt.scatter(x = range(73), y = df.Real, c = 'r')
plt.xlabel('Indexes Sorted By Real Age')
plt.ylabel('Age')
plt.suptitle('Comparing Real and Predicted Ages by Index (Validation Set)')

plt.legend((pr, re),
  ('Predicted', 'Real'),
  scatterpoints=1,
  loc='upper left',
  ncol=1,
  fontsize=8)

plt.savefig('Comparing Real and Predicted Ages by Index (Validation Set)')
plt.show()

## Comparing Real and Predicted Ages by Index (Training Set)
df = pd.DataFrame({"Real":y_train, "Pred":y_.reshape(656)})
df = df.sort_values(by=['Real'])
pr = plt.scatter(x = range(656), y = df.Pred, c = 'b')
re = plt.scatter(x = range(656), y = df.Real, c = 'r')
plt.xlabel('Indexes Sorted By Real Age')
plt.ylabel('Age')
plt.suptitle('Comparing Real and Predicted Ages by Index (Training Set)')

plt.legend((pr, re),
  ('Predicted', 'Real'),
  scatterpoints=1,
  loc='upper left',
  ncol=1,
  fontsize=8)

plt.savefig('Comparing Real and Predicted Ages by Index (Training Set)')
plt.show()


## Plotting Predicted Age against Real Age (Validation Set)
plt.scatter(x=y_test, y=y.reshape(73))
np.save("y_valid_real.npy", y_test)
np.save("y_valid_pred.npy", y.reshape(73))

plt.xlabel('Real Age')
plt.ylabel('Predicted Age')
plt.suptitle('Plotting Predicted Age against Real Age (Validation Set)')

plt.savefig('Plotting Predicted Age against Real Age (Validation Set)')
plt.show()


## Plotting Predicted Age against Real Age (Training Set)
plt.scatter(x=y_train, y=y_.reshape(656), c='b')

plt.xlabel('Real Age')
plt.ylabel('Predicted Age')
plt.suptitle('Plotting Predicted Age against Real Age (Training Set)')

plt.savefig('Plotting Predicted Age against Real Age (Training Set)')
plt.show()

print(data_numpy_del.shape)
print(data_numpy_chi.shape)

data_head = data_numpy_chi.T
df_heat_red = pd.DataFrame(data_head)
df_heat_red = df_heat_red.T.set_index(annotations.index)
print(df_heat_red.shape)
print(annotations["Age_Group"].shape)
annotations = annotations.dropna()
print(annotations["Age_Group"])
print(df_heat_red.index)
print(annotations.index)

df_heat_red["Age"] = annotations["Age_Group"]
print(df_heat_red["Age"])



cmap = sns.diverging_palette(118, 0, sep=10, center="dark", as_cmap=True)

#print(df_heat_red.head())
print(df_heat_red.head())
df_heat_red["Age"] = annotations["Age_Group"]
df_heat_red = df_heat_red.sort_values("Age")
print(df_heat_red.head())
df_heat_red = df_heat_red.drop("Age", axis=1)
sns.heatmap(df_heat_red.T, annot=False)

model.save_weights("nn weights")

model = tf.keras.models.Sequential([
    tf.keras.layers.Reshape((4, 4, 1), input_shape=(16,)),
    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same'),
    tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu',padding='same'),
    #tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    # tf.keras.layers.Dense(256, activation='relu'),
    # tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    #tf.keras.layers.Dense(2, activation='softmax')
    tf.keras.layers.Dense(1)
])